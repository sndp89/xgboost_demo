{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to XGBoost with RAPIDS\n",
    "\n",
    "In this notebook, we'll show the acceleration one can gain by using GPUs with XGBoost in RAPIDS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hardware setup\n",
    "\n",
    "To start, let's see what hardware we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T21:03:38.237293Z",
     "start_time": "2018-11-06T21:03:37.388285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Feb  6 09:16:41 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 410.79       Driver Version: 410.79       CUDA Version: 10.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-DGXS...  On   | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    40W / 300W |      0MiB / 16128MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-DGXS...  On   | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    41W / 300W |      0MiB / 16128MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-DGXS...  On   | 00000000:0E:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    41W / 300W |      0MiB / 16128MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-DGXS...  On   | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    41W / 300W |      0MiB / 16128MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "!nproc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA Version\n",
    "\n",
    "Next, let's see what CUDA version we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T21:03:39.490984Z",
     "start_time": "2018-11-06T21:03:39.134608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2018 NVIDIA Corporation\n",
      "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
      "Cuda compilation tools, release 10.0, V10.0.130\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load our libraries\n",
    "\n",
    "Let's load some of the libraries within the RAPIDs ecosystem and see which versions we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T21:03:41.067879Z",
     "start_time": "2018-11-06T21:03:40.256654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuDF Version: 0.5.0+6.g5d5919d\n",
      "numba Version: 0.42.0\n",
      "numpy Version: 1.15.4\n",
      "matplotlib Version: 3.0.2\n",
      "pandas Version: 0.24.0\n",
      "pyarrow Version: 0.11.1\n",
      "XGBoost Version: 0.81\n"
     ]
    }
   ],
   "source": [
    "import cudf; print('cuDF Version:', cudf.__version__)\n",
    "#import cuml; print('cuML Version:', '0.2.0')\n",
    "#import dask; print('dask Version:', dask.__version__)\n",
    "# import dask_gdf; print('dask_gdf Version:', dask_gdf.__version__)\n",
    "# import dask_xgboost; print('dask_xgboost Version:', dask_xgboost.__version__)\n",
    "import numba; print('numba Version:', numba.__version__)\n",
    "import numpy; print('numpy Version:', numpy.__version__)\n",
    "import matplotlib; print('matplotlib Version:', matplotlib.__version__)\n",
    "import pandas; print('pandas Version:', pandas.__version__)\n",
    "import pyarrow; print('pyarrow Version:', pyarrow.__version__)\n",
    "import xgboost; print('XGBoost Version:', xgboost.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load/Simulate data\n",
    "\n",
    "### Load data\n",
    "\n",
    "We can load the data using `pandas.read_csv`.\n",
    "\n",
    "### Simulate data\n",
    "\n",
    "Alternatively, we can simulate data for our train and validation datasets. The features will be tabular with `n_rows` and `n_columns` in the training dataset, where each value is either of type `np.float32` if the data is numerical or `np.uint8` if the data is categorical. Both numerical and categorical data can also be combined; for this experiment, we have ignored this combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# helper function for simulating data\n",
    "def simulate_data(m, n, k=2, numerical=False):\n",
    "    if numerical:\n",
    "        features = np.random.rand(m, n)\n",
    "    else:\n",
    "        features = np.random.randint(2, size=(m, n))\n",
    "    labels = np.random.randint(k, size=m)\n",
    "    return np.c_[labels, features].astype(np.float32)\n",
    "\n",
    "\n",
    "# helper function for loading data\n",
    "def load_data(filename, n_rows):\n",
    "    if n_rows >= 1e9:\n",
    "        df = pd.read_csv(filename)\n",
    "    else:\n",
    "        df = pd.read_csv(filename, nrows=n_rows)\n",
    "    return df.values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "LOAD = False\n",
    "n_gpus = 4\n",
    "n_rows = int(1e8)\n",
    "n_columns = int(100)\n",
    "n_categories = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000000, 101)\n",
      "CPU times: user 1min 23s, sys: 59.3 s, total: 2min 23s\n",
      "Wall time: 2min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if LOAD:\n",
    "    dataset = load_data('/tmp', n_rows)\n",
    "else:\n",
    "    dataset = simulate_data(n_rows, n_columns, n_categories)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data\n",
    "\n",
    "We'll split our dataset into a 80% training dataset and a 20% validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify shape and indices\n",
    "n_rows, n_columns = dataset.shape\n",
    "train_size = 0.80\n",
    "train_index = int(n_rows * train_size)\n",
    "\n",
    "# split X, y\n",
    "X, y = dataset[:, 1:], dataset[:, 0]\n",
    "del dataset\n",
    "\n",
    "# split train data\n",
    "X_train, y_train = X[:train_index, :], y[:train_index]\n",
    "\n",
    "# split validation data\n",
    "X_validation, y_validation = X[train_index:, :], y[train_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check dimensions\n",
    "\n",
    "We can check the dimensions and proportions of our training and validation dataets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train[:3, :], y_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (80000000, 100) float32 y_train:  (80000000,) float32\n",
      "X_validation (20000000, 100) float32 y_validation:  (20000000,) float32\n",
      "X_train proportion: 0.8\n",
      "X_validation proportion: 0.2\n"
     ]
    }
   ],
   "source": [
    "# check dimensions\n",
    "print('X_train: ', X_train.shape, X_train.dtype, 'y_train: ', y_train.shape, y_train.dtype)\n",
    "print('X_validation', X_validation.shape, X_validation.dtype, 'y_validation: ', y_validation.shape, y_validation.dtype)\n",
    "\n",
    "# check the proportions\n",
    "total = X_train.shape[0] + X_validation.shape[0]\n",
    "print('X_train proportion:', X_train.shape[0] / total)\n",
    "print('X_validation proportion:', X_validation.shape[0] / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert NumPy data to DMatrix format\n",
    "\n",
    "With out data simulated and formatted as NumPy arrays, our next step is to convert this to a `DMatrix` object that XGBoost can work with. We can instantiate an object of the `xgboost.DMatrix` by passing in the feature matrix as the first argument followed by the label vector using the `label=` keyword argument. To learn more about XGBoost's support for data structures other than NumPy arrays, see the documentation for the Data Interface:\n",
    "\n",
    "\n",
    "https://xgboost.readthedocs.io/en/latest/python/python_intro.html#data-interface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T21:03:55.278322Z",
     "start_time": "2018-11-06T21:03:54.059643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.2 s, sys: 34.2 s, total: 1min 18s\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dvalidation = xgb.DMatrix(X_validation, label=y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters\n",
    "\n",
    "There are a number of parameters that can be set before XGBoost can be run. \n",
    "\n",
    "* General parameters relate to which booster we are using to do boosting, commonly tree or linear model\n",
    "* Booster parameters depend on which booster you have chosen\n",
    "* Learning task parameters decide on the learning scenario. For example, regression tasks may use different parameters with ranking tasks.\n",
    "\n",
    "For more information on the configurable parameters within the XGBoost module, see the documentation here:\n",
    "\n",
    "\n",
    "https://xgboost.readthedocs.io/en/latest/parameter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T21:03:57.443698Z",
     "start_time": "2018-11-06T21:03:57.438288Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'silent': 1, 'tree_method': 'gpu_hist', 'n_gpus': 4, 'eval_metric': 'auc', 'objective': 'binary:logistic'}\n"
     ]
    }
   ],
   "source": [
    "# instantiate params\n",
    "params = {}\n",
    "\n",
    "# general params\n",
    "general_params = {'silent': 1}\n",
    "params.update(general_params)\n",
    "\n",
    "# booster params\n",
    "# n_gpus = 0\n",
    "booster_params = {}\n",
    "\n",
    "if n_gpus != 0:\n",
    "    #booster_params['tree_method'] = 'hist'\n",
    "    booster_params['tree_method'] = 'gpu_hist'\n",
    "    booster_params['n_gpus'] = n_gpus\n",
    "params.update(booster_params)\n",
    "\n",
    "# learning task params\n",
    "learning_task_params = {'eval_metric': 'auc', 'objective': 'binary:logistic'}\n",
    "params.update(learning_task_params)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "Now it's time to train our model! We can use the `xgb.train` function and pass in the parameters, training dataset, the number of boosting iterations, and the list of items to be evaluated during training. For more information on the parameters that can be passed into `xgb.train`, check out the documentation:\n",
    "\n",
    "\n",
    "https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training settings\n",
    "evallist = [(dvalidation, 'validation'), (dtrain, 'train')]\n",
    "num_round = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T21:04:50.201308Z",
     "start_time": "2018-11-06T21:04:00.363740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-auc:0.499899\ttrain-auc:0.501386\n",
      "[1]\tvalidation-auc:0.49994\ttrain-auc:0.501902\n",
      "[2]\tvalidation-auc:0.499991\ttrain-auc:0.502274\n",
      "[3]\tvalidation-auc:0.499997\ttrain-auc:0.502577\n",
      "[4]\tvalidation-auc:0.500051\ttrain-auc:0.502852\n",
      "[5]\tvalidation-auc:0.499991\ttrain-auc:0.503102\n",
      "[6]\tvalidation-auc:0.500077\ttrain-auc:0.503304\n",
      "[7]\tvalidation-auc:0.500082\ttrain-auc:0.503524\n",
      "[8]\tvalidation-auc:0.500113\ttrain-auc:0.503707\n",
      "[9]\tvalidation-auc:0.500131\ttrain-auc:0.50389\n",
      "[10]\tvalidation-auc:0.500157\ttrain-auc:0.504077\n",
      "[11]\tvalidation-auc:0.500166\ttrain-auc:0.504242\n",
      "[12]\tvalidation-auc:0.500185\ttrain-auc:0.504397\n",
      "[13]\tvalidation-auc:0.500166\ttrain-auc:0.504542\n",
      "[14]\tvalidation-auc:0.500122\ttrain-auc:0.504704\n",
      "[15]\tvalidation-auc:0.500099\ttrain-auc:0.504856\n",
      "[16]\tvalidation-auc:0.500074\ttrain-auc:0.505006\n",
      "[17]\tvalidation-auc:0.500055\ttrain-auc:0.505141\n",
      "[18]\tvalidation-auc:0.50003\ttrain-auc:0.505261\n",
      "[19]\tvalidation-auc:0.500054\ttrain-auc:0.505387\n",
      "[20]\tvalidation-auc:0.500035\ttrain-auc:0.505537\n",
      "[21]\tvalidation-auc:0.500061\ttrain-auc:0.505656\n",
      "[22]\tvalidation-auc:0.500015\ttrain-auc:0.505775\n",
      "[23]\tvalidation-auc:0.50003\ttrain-auc:0.505917\n",
      "[24]\tvalidation-auc:0.500036\ttrain-auc:0.506032\n",
      "[25]\tvalidation-auc:0.500026\ttrain-auc:0.506145\n",
      "[26]\tvalidation-auc:0.50005\ttrain-auc:0.506261\n",
      "[27]\tvalidation-auc:0.500074\ttrain-auc:0.506369\n",
      "[28]\tvalidation-auc:0.500076\ttrain-auc:0.506492\n",
      "[29]\tvalidation-auc:0.500076\ttrain-auc:0.506593\n",
      "[30]\tvalidation-auc:0.500119\ttrain-auc:0.506689\n",
      "[31]\tvalidation-auc:0.500113\ttrain-auc:0.506795\n",
      "[32]\tvalidation-auc:0.500104\ttrain-auc:0.506883\n",
      "[33]\tvalidation-auc:0.500143\ttrain-auc:0.506977\n",
      "[34]\tvalidation-auc:0.500175\ttrain-auc:0.507085\n",
      "[35]\tvalidation-auc:0.500149\ttrain-auc:0.507169\n",
      "[36]\tvalidation-auc:0.500133\ttrain-auc:0.507278\n",
      "[37]\tvalidation-auc:0.500141\ttrain-auc:0.507371\n",
      "[38]\tvalidation-auc:0.500127\ttrain-auc:0.507464\n",
      "[39]\tvalidation-auc:0.500081\ttrain-auc:0.507566\n",
      "[40]\tvalidation-auc:0.500087\ttrain-auc:0.507654\n",
      "[41]\tvalidation-auc:0.500084\ttrain-auc:0.507732\n",
      "[42]\tvalidation-auc:0.500036\ttrain-auc:0.507818\n",
      "[43]\tvalidation-auc:0.500016\ttrain-auc:0.507913\n",
      "[44]\tvalidation-auc:0.500031\ttrain-auc:0.507982\n",
      "[45]\tvalidation-auc:0.500041\ttrain-auc:0.508062\n",
      "[46]\tvalidation-auc:0.500057\ttrain-auc:0.508134\n",
      "[47]\tvalidation-auc:0.500043\ttrain-auc:0.508204\n",
      "[48]\tvalidation-auc:0.500037\ttrain-auc:0.508275\n",
      "[49]\tvalidation-auc:0.500018\ttrain-auc:0.508345\n",
      "[50]\tvalidation-auc:0.500035\ttrain-auc:0.508419\n",
      "[51]\tvalidation-auc:0.50006\ttrain-auc:0.508485\n",
      "[52]\tvalidation-auc:0.500085\ttrain-auc:0.50856\n",
      "[53]\tvalidation-auc:0.500081\ttrain-auc:0.508634\n",
      "[54]\tvalidation-auc:0.500074\ttrain-auc:0.508703\n",
      "[55]\tvalidation-auc:0.500078\ttrain-auc:0.50877\n",
      "[56]\tvalidation-auc:0.500076\ttrain-auc:0.508841\n",
      "[57]\tvalidation-auc:0.50009\ttrain-auc:0.508913\n",
      "[58]\tvalidation-auc:0.50008\ttrain-auc:0.508985\n",
      "[59]\tvalidation-auc:0.500074\ttrain-auc:0.50904\n",
      "[60]\tvalidation-auc:0.500053\ttrain-auc:0.509107\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bst = xgb.train(params, dtrain, num_round, evallist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
